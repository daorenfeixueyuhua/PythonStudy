爬虫简介：
	一段自动抓取互联网信息的程序
	价值：互联网数据，为我所用

简单爬虫架构
	爬虫调度端：url管理器->网页下载器->网页解析器
	运行流程

URL管理器
	防止重复抓取，防止循环抓取
	实现：
		内存：python set()集合
		关系数据库：MYSQL
		缓存数据库：Redis

网页下载器：
	将url对应的网页下载到本地
	urllib2
	requests

	urllib2:
		方法1：
			import urllib2
			response=urllib2.urlopen("http://baidu.com")
			print("response.getcode()")
			cont=response.read()
		方法2：添加data、http_header
			import urllib2
			request=urlib2.Request(url)
			request.add_data('a','1')
			request.add_header('User-Agent','Mozilla/5.0')
			response=urllib2.urlopen(request)
		方法3：添加特殊情景的处理器
			HTTPCookieProcessor	ProxyHandler	HTTPSHandler	HTTPRedirectHandler
			opener=urllib2.bulid_opener(handler)
			urllib2.insyall_opener(opener)
			urllib2.urlopen(url)
			urllib2.urlopen(request)
//测试提交